{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Houston Local Hack Day at University fo Houston PGH 232\n",
    "### Team: Anooj Shah, Lucas Atayde, Kari Burt, Jennifer Cai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction and Motivation\n",
    "\n",
    "The team decided to use sentiment analysis on user input. We were aware of what sentiment analysis was, but we are new to NPL and our first attempt at implementing in python. I went and looked up more information about NLP from https://en.wikipedia.org/wiki/Sentiment_analysis Some things I didn't expect were \"Emoji Sentiment Ranking\" which makes sense but I would not have thought of it without reading about it\n",
    "\n",
    "The resources we used include the following\n",
    "- https://en.wikipedia.org/wiki/Sentiment_analysis\n",
    "- https://textblob.readthedocs.io/en/dev/quickstart.html#quickstart\n",
    "- https://planspace.org/20150607-textblob_sentiment/\n",
    "- https://www.lexalytics.com/technology/sentiment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Early Challenges and Binder\n",
    "\n",
    "Our team is novice to collaborating via Github. We had some initial challenge sharing code. As always first time setup is a challenge and one of our concerns was reproducability / deployment. To compensate I tried to deploy using binder for the first time. My strategy to share is to fork our main repo, https://github.com/anooj-shah/localhack, and then submit pull requests. This notebook was uploaded to binder for easier integration.\n",
    "\n",
    "### The Project and the Plan\n",
    "\n",
    "Our team wanted to develop a mental health application. In this step I am reading a csv of timestamps and text as a list. This information is being passed through TextBlob to run sentiment analysis. The output is written to a CSV for processing by data visualization team.\n",
    "\n",
    "**Meet the Team**\n",
    "- **Lucas** has been building a Python app using the Twilio API\n",
    "- **Jennifer** has been working on using TextBlob to do sentiment analysis and write to CSV\n",
    "- **Anooj** is managing our Github and taking care of the visualizations\n",
    "- **Kari** is putting it all together with her web development skills\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### A quick explanation of TextBlob from https://planspace.org/20150607-textblob_sentiment/\n",
    "\n",
    "Each word in the lexicon has scores for:\n",
    " 1. polarity: negative vs. positive    (-1.0 => +1.0)\n",
    " 2. subjectivity: objective vs. subjective (+0.0 => +1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sentiment Analysis with Python Notebook\n",
    "\n",
    "In the planning stages, we decided that Lucas would generate a CSV of two columns, time stamp and user input string. I generated a dummy_input.csv for testing using various random news articles and Reddit posts. Lucas also contributed dummy input by using pop songs as quality control. In this step we read the CSV input and parse it to the TextBlob library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "#Initialize the lists\n",
    "\n",
    "output_list = []\n",
    "QC_list = []\n",
    "\n",
    "#Open the CSV of input\n",
    "\n",
    "infile = open(\"feelings.csv\", 'r')\n",
    "\n",
    "#Read every line in the input\n",
    "#Process data, the date is transformed to mm/dd/yyyy and only hour is sliced\n",
    "#Place into the respective list\n",
    "\n",
    "for line in infile:\n",
    "    data = line.split(',')\n",
    "    full_time = data[0]\n",
    "    date = (full_time[5:7] + \"-\" + full_time[9:10] + \"-\" + full_time[:4])\n",
    "    hour = (full_time[11:13])\n",
    "    blob = TextBlob(data[1])\n",
    "    output_list.append((date, hour, blob.sentiment.polarity))\n",
    "    QC_list.append((blob.sentiment, data[1]))\n",
    "infile.close()\n",
    "\n",
    "#Write the output to a csv file\n",
    "#Columns are Date, Time, and Sentiment Score\n",
    "#This CSV is used for the visualization on the web interface\n",
    "outfile = open(\"output.csv\", 'w')\n",
    "for item in output_list:\n",
    "    outfile.write(item[0]+\",\"+item[1]+\",\"+str(item[2])+\"\\n\")\n",
    "outfile.close()\n",
    "\n",
    "#Wirte a file for QC\n",
    "#This is the Sentiment Polarity (-1 to 1), Subjectivity, and the full text\n",
    "outfile = open(\"QC_output.csv\", 'w')\n",
    "for item in QC_list:\n",
    "    outfile.write(str(item[0])+\",\"+str(item[1])+\"\\n\")\n",
    "outfile.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=1.0, subjectivity=0.75),I feel great!\n",
      "\n",
      "Sentiment(polarity=0.0, subjectivity=0.0),Today I got passed over for a promotion ðŸ˜”\n",
      "\n",
      "Sentiment(polarity=0.55, subjectivity=0.875),Wow today is great!\n",
      "\n",
      "Sentiment(polarity=0.0, subjectivity=0.0),Rest In Peace my GPA\n",
      "\n",
      "Sentiment(polarity=0.2676136363636364, subjectivity=0.6636363636363637),I got a new job! I'm so happy I can finally leave my old place.\n",
      "\n",
      "Sentiment(polarity=-0.20454545454545456, subjectivity=0.5959595959595959),First day in the job was well yikes. The traffic was terrible and my new boss hates me.\n",
      "\n",
      "Sentiment(polarity=0.5, subjectivity=0.6),Day two on the job I learned how to sneak snacks into my cubicle. I love eating candy all day\n",
      "\n",
      "Sentiment(polarity=0.5, subjectivity=0.6),I love puppies\n",
      "\n",
      "Sentiment(polarity=0.5792857142857142, subjectivity=0.7428571428571427),When you were here before Couldn't look you in the eye You're just like an angel Your skin makes me cry You float like a feather In a beautiful world I wish I was special You're so fucking special  But I'm a creep I'm a weirdo What the hell am I doing here? I don't belong here  I don't care if it hurts I want to have control I want a perfect body I want a perfect soul I want you to notice When I'm not around You're so fucking special I wish I was special  But I'm a creep I'm a weirdo What the hell am I doing here? I don't belong here  Oh oh  She's running out again She's running out She run run run run Run  Whatever makes you happy Whatever you want You're so fucking special I wish I was special  But I'm a creep I'm a weirdo What the hell am I doing here? I don't belong here I don't belong here 2018-12-01 14:52:47.354046\n",
      "\n",
      "Sentiment(polarity=0.1416666666666667, subjectivity=0.725),“This incredible artist had ALS and had been lying motionless in bed for 7 years… we were determined to help him draw again.” Mick Ebeling and Not Impossible Labs tackle the impossible every day. What should they tackle next?\n",
      "\n",
      "Sentiment(polarity=-0.125, subjectivity=0.225),A month ago I applied for a small loan at Wells Fargo for the 1st time ever to consolidate some small bills. They denied the loan. I went to a local Credit Union and they gave me the loan. Today I signed up for a checking/savings account at that Credit Union and canceled my accounts with Wells Fargo. Couldn't be happier to stop doing business with a crooked ass corporation.\n",
      "\n",
      "Sentiment(polarity=-0.10277777777777779, subjectivity=0.29351851851851857),My wife and I lived on the west coast and I had to leave my job (internship expired). We were running shorter and shorter on cash and were forced to break out our credit card to stay afloat for a while. We used it for rent a few times (big no-no) and for lots of other things. We were both miserable out there so we moved to the midwest in June of 2018. By the time the move was over we had about 4k racked up on the card. We both found good jobs after our move and I wanted this debt gone. This morning I made my last payment of 400 dollars and we now have a 0 balance on the card! Now we can actually start putting some money away!\n",
      "\n",
      "Sentiment(polarity=0.0, subjectivity=0.04786324786324786),Khashoggi an outspoken critic of the Saudi crown prince was murdered inside the Saudi consulate in Istanbul. He had left Saudi Arabia in self-imposed exile last year and settled in the US state of Virginia where he was a regular contributor to The Washington Post.\n",
      "\n",
      "Sentiment(polarity=0.2505050505050505, subjectivity=0.5646464646464647),Parents who force unremorseful kids to apologize to others before they’re truly sorry may do more harm than good suggests a new study. That’s because the point main point of an apology is lost as children may dislike the apologizer even more after the insincere apology than before.\n",
      "\n",
      "Sentiment(polarity=0.0, subjectivity=0.75),\"I've heard from countless people that Python is \"\"slower\"\" than languages like C++ I was wondering how this affects the final product - as in web applications in terms of latency times for users etc?\"\n",
      "\n",
      "Sentiment(polarity=-0.006944444444444443, subjectivity=0.29583333333333334),I’ve tried applying it daily on my lashes for 2 weeks and noticed such DRAMATIC difference. My lashes were much much longer and thicker. However as soon as I stopped applying it every day my lashes started falling out more than usual (3-4 per day as opposed to 1-2 per day). The shedding lasted for a few days then it went back to normal. It has been a few months now since I stopped and my lashes are now back at their normal length/density.\n",
      "\n",
      "Sentiment(polarity=0.12000000000000002, subjectivity=0.28),It took our whole team months to plan and prepare this big initiative to promote our platform. And it took even longer to get our platform to the point where it delivered real value for people and to be ready for big promotion. Please support and share if it's something that might interest you or someone you know.\n",
      "\n",
      "Sentiment(polarity=0.13999999999999999, subjectivity=0.4377777777777778),Hey guys I've been working on learning Javascript for a month or so now and the hardest part has been getting it set up to even see what my code does. This week I finally managed to get a local web server running on my machine using node.js but I wasn't sure if I really understood I was doing. Today while looking for a tutorial on the $.getJSON function I came across a paragraph on setting up a web server and realized that it actually made sense to me! It goes:\n",
      "\n",
      "Sentiment(polarity=0.375, subjectivity=0.44583333333333336),\"\"\"Jeb Neil Marvin Doro and I are saddened to announce that after 94 remarkable years our dear Dad has died\"\" said former President George W. Bush in a statement. \"\"George H. W. Bush was a man of the highest character and the best dad a son or daughter could ask for. The entire Bush family is deeply grateful for 41’s life and love for the compassion of those who have cared and prayed for Dad and for the condolences of our friends and fellow citizens.\"\"\"\n",
      "\n",
      "Sentiment(polarity=0.13611111111111113, subjectivity=0.5108024691358025),\"I have a list of player point projections the results and the absolute value of the amount missed by. I want to get a picture on how accurate the projections are. I am not the best with stats took one class in college and most of what I know comes from excel anyways so I am not exactly sure how to approach this. My thoughts are that I want to get the Variation for my \"\"missed by\"\" column then get the Standard Deviation of the Variation then get the Mean missed by. Then I could get the standard error and find a confidence interval so I could see that 99% of all projections were within +x and -x where x = Mean miss +/- the CI.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#This is an example of how the data is being processed\n",
    "\n",
    "for item in QC_list:\n",
    "    print(str(item[0])+\",\"+str(item[1])+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11-1-2018,3,-0.4445565591688916\n",
      "11-2-2018,3,0.9244531945645638\n",
      "11-3-2018,10,0.6689143022684716\n",
      "11-4-2018,17,0.8308197675024411\n",
      "11-5-2018,19,-0.14348502563002308\n",
      "11-6-2018,4,-0.21406216979890003\n",
      "11-7-2018,9,-0.29918519527402276\n",
      "11-8-2018,16,-0.23807184305270157\n",
      "11-9-2018,19,0.2921593021551492\n",
      "11-10-2018,22,0.9281803447082064\n",
      "11-11-2018,13,0.9102256139090921\n",
      "11-12-2018,13,0.11714507243346661\n",
      "11-13-2018,14,0.3868305688271392\n",
      "11-14-2018,22,-0.9469808940360427\n",
      "11-15-2018,22,-0.41005185863381466\n",
      "11-16-2018,9,-0.13009929906427686\n",
      "11-17-2018,17,-0.3674145640081907\n",
      "11-18-2018,4,0.7655305400854644\n",
      "11-19-2018,0,-0.9661020337690942\n",
      "11-20-2018,15,0.705257223210707\n",
      "11-21-2018,23,-0.5399866821023354\n",
      "11-22-2018,20,0.703388130345119\n",
      "11-23-2018,22,-0.27985859371032373\n",
      "11-24-2018,0,-0.49414554001010114\n",
      "11-25-2018,13,0.34958063157936503\n",
      "11-26-2018,21,-0.7533300704940467\n",
      "11-27-2018,10,-0.9240558979892479\n",
      "11-28-2018,17,-0.058131714905995\n",
      "11-29-2018,3,-0.10466763988808614\n",
      "11-30-2018,9,0.4436922612613394\n"
     ]
    }
   ],
   "source": [
    "#Here is an eample of how the data lookswhen processed for visualization\n",
    "\n",
    "for item in output_list:\n",
    "    print(str(item[0])+\",\"+str(item[1])+\",\"+str(item[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Things we learned\n",
    "\n",
    "- **Lucas** has evolved into a GitHub God, Python 3 Expert, and HTTP Evangelist\n",
    "- **Jennifer** introduced the team to Jupyter Notebooks, but she is also new to deploying on Binder and using Jupyter Slides\n",
    "- **Anooj** has become a matplotlib artist\n",
    "- **Kari** was too busy utilizing her expert Web Dev skills but plans to dive deeper into Python\n",
    "\n",
    "We all learned a little bit about teamwork 😄 #HoustonHackDay"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
